---
pubDatetime: 2026-02-24
title: "面对 AI 伤害，我们可以立刻做的几件事"
description: "这篇文章把抽象的 AI 风险转成可执行的日常行动，聚焦孩子安全与组织责任。你可以从公司社媒策略和学校技术采购两条线同时推进，用清晰问题触发管理层承担责任，并联合同事、家长和社区形成持续推动力。"
tags: ["AI", "AI Safety", "Child Safety", "Digital Governance"]
slug: "taking-action-against-ai-harms"
source: "https://anildash.com/2026/02/23/taking-action-ai-harms/"
---

很多人都知道 AI 平台正在带来真实伤害，尤其会影响孩子，但一想到要推动立法或大型公共运动，就容易觉得无从下手。

原文作者给了一个很实用的方向：先做你今天就能做的动作，从身边的组织流程入手，把“担忧”变成“可追踪、可问责”的沟通。

## 背景

这篇文章延续了作者上一文《How did we end up threatening our kids’ lives with AI?》的讨论。前一篇重点解释了为什么问题会发生，这一篇则专注于如何采取行动。

核心观点很明确：系统层面的治理当然重要，但个人层面的动作同样关键。很多改变，都是从一封邮件、一次会议发问开始。

## 关键要点

### 1）推动公司退出高风险平台

如果你的公司仍在使用 X（Twitter）或正在集成相关 AI 能力，作者建议你把讨论拉回到员工安全与企业合规上。

你可以向主管、法务、人力资源提出具体问题，例如：

- 团队是否必须在该平台执行工作职责
- 如果员工在履职中接触到违法或有害内容，公司流程如何保护员工
- 公司是否愿意明确承担由此产生的法律与心理健康风险

这类问题的价值在于让管理层明确表态，并留下书面记录。

作者还建议同步与同事沟通，必要时咨询本地劳动法律资源，避免个人单独承压。

### 2）阻止学校仓促引入高风险聊天机器人

第二个行动场景是学校。作者认为，学校常被“AI 是未来，必须立刻上”这类叙事推动，结果在缺乏充分安全评估时直接把工具交给孩子。

实操上可以先准备可信报道和案例，再与校方沟通。常见反驳包括“个别事件”“所有工具都一样”“只是小范围试点”。

回应思路是聚焦孩子现实安全：

- 是否有完善监护与干预机制
- 谁负责持续监测使用风险
- 家长是否被充分告知并同意承担额外责任

把问题放在儿童保护和责任分配上，通常更容易形成共识。

### 3）你有可用的影响力

作者最后强调，行动并不遥远。和民选代表沟通、参与本地社区组织、在工作中拒绝把高风险平台“正常化”，这些都能产生累积效应。

当更多普通人提出清晰问题并要求清晰回答，组织会开始调整策略。改变往往来自许多看似很小的动作叠加。

## 实践建议

如果你希望今天就开始，可以按这个顺序：

1. 选一个最贴近你的场景，工作单位或孩子所在学校。
2. 准备 2 到 3 条可核验的事实来源，避免泛泛表达。
3. 发出一封简短邮件，只问关键责任问题，并抄送相关责任方。
4. 邀请一位同事或家长共同跟进，形成连续沟通。
5. 记录每次回复与承诺，便于后续追踪。

你不需要一次解决所有问题。先把第一步做出来，后面的路会清楚很多。