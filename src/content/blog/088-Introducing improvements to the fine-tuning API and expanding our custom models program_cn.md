---
pubDatetime: 2024-04-07
tags: []
source: https://openai.com/blog/introducing-improvements-to-the-fine-tuning-api-and-expanding-our-custom-models-program
author: 作者
title: 介绍对微调 API 的改进以及扩展我们的自定义模型程序
description: 我们正在添加新功能以帮助开发者更好地控制微调，并宣布与 OpenAI 一起构建自定义模型的新方法。
---

> ## 摘录
>
> 我们正在添加新功能以帮助开发者更好地控制微调，并宣布与 OpenAI 一起构建自定义模型的新方法。
>
> 原文链接 [Introducing improvements to the fine-tuning API and expanding our custom models program](https://openai.com/blog/introducing-improvements-to-the-fine-tuning-api-and-expanding-our-custom-models-program)

---

开发者可以使用多种[技术](https://www.youtube.com/watch?v=ahnGLM-RC1Y&list=PLOXw6I10VTv-exVCRuRjbT6bqkfO74rWz&index=4)来提高模型性能，以减少延迟、提高准确性并降低成本。无论是通过检索增强生成（RAG）扩展模型知识，通过微调定制模型行为，还是构建具有新的领域特定知识的自定义训练模型，我们都开发了一系列选项来支持我们客户的 AI 实现。今天，我们正在推出新功能以让开发者在使用 API 进行微调时拥有更多控制权，并介绍与我们的 AI 专家和研究人员团队合作构建自定义模型的更多方式。

## 新的微调 API 功能

我们于 2023 年 8 月为 GPT-3.5 推出了自助服务的[微调 API](https://platform.openai.com/docs/guides/fine-tuning)。从那时起，数千个组织已经使用我们的 API 训练了数以百万计的模型。微调可以帮助模型深入理解内容，并增加模型现有知识和特定任务的能力。我们的微调 API 还支持比单个提示可以容纳的更大量的示例，以实现更高质量的结果，同时降低成本和延迟。微调的一些常见用例包括训练模型以更好地生成特定编程语言的代码、以特定格式总结文本或根据用户行为创建个性化内容。

例如，全球就业匹配和招聘平台 [Indeed](https://www.indeed.com/) 希望简化招聘过程。作为此举措的一部分，Indeed 推出了一项功能，向求职者发送个性化推荐，突出显示基于他们的技能、经验和偏好的相关工作。他们微调了 GPT-3.5 Turbo 以生成更高质量和更准确的解释。结果，Indeed 能够通过将提示中的令牌数量减少 80％ 来改善成本和延迟。这让他们的信息发送量从每月不到一百万条增加到大约 2000 万条。

今天，我们正在引入[新功能](https://platform.openai.com/docs/guides/fine-tuning/create-a-fine-tuned-model)以给予开发者对他们微调作业的更多控制，包括：

- **基于周期的检查点创建：**在每个训练周期期间自动产生一个完整的微调模型检查点，这样可以减少随后重新训练的需要，特别是在过拟合的情况下
- **比较 Playground：**一个新的并排 Playground UI，用于比较单个提示下多个模型或微调快照的质量和性能，允许对模型输出进行人类评价
- **第三方集成：**支持与第三方平台（本周开始与 [Weights and Biases](https://wandb.ai/site)）的集成，让开发者将详细的微调数据分享到他们的其他技术栈
- **全面的验证指标：**能够计算整个验证数据集（而不是采样批次）上的损失和准确性等指标，提供更好的模型质量洞察
- **超参数配置：**能够从[仪表板](https://platform.openai.com/finetune)（而不仅仅是通过 API 或 SDK）配置可用的超参数
- **微调仪表板改进：**包括能够配置超参数、查看更详细的训练指标以及根据之前的配置重新运行作业

![API 中的微调](../../assets/88/fine-tuning-in-api.gif)

## 扩展我们的自定义模型计划

**辅助微调**

在去年 11 月的 DevDay 上，我们[宣布](https://openai.com/blog/new-models-and-developer-products-announced-at-devday)了一个旨在为特定领域训练和优化模型的自定义模型计划，与一组专 dedicated 的 OpenAI 研究者合作。从那时起，我们已经与数十个客户会面，评估他们的自定义模型需求，并发展了我们的计划，以进一步最大化性能。

今天，我们正式宣布作为自定义模型计划的一部分提供辅助微调服务。辅助微调是我们技术团队的合作努力，利用微调 API 之外的技术，如额外的超参数和各种参数有效的微调（PEFT）方法进行大规模使用。对于需要支持设置高效的训练数据管道、评估系统和为了最大化其用例或任务的模型性能而定制的特殊参数和方法的组织来说，这一点尤其有帮助。

例如，服务于韩国超过 3000 万用户的电信运营商 [SK Telecom](https://www.sktelecom.com/index_en.html) 希望定制一个在电信领域具有专家知识的模型，最初侧重于客户服务。他们与 OpenAI 合作，对 GPT-4 进行了微调，以提高其在韩语电信相关对话中的性能。在几周的时间里，SKT 和 OpenAI 在电信客户服务任务中取得了有意义的性能改进 - 会话总结质量增加了 35%，意图识别准确性增加了 33%，并且在将微调模型与 GPT-4 比较时，满意度得分从 3.6 上升到 4.5（满分为 5）。

**定制训练模型**

在某些情况下，组织需要从头开始训练一个针对其业务、行业或领域理解的定制模型。完全定制训练的模型通过修改模型训练过程的关键步骤，并使用新颖的中训练和训练后技术，将特定领域的新知识融入其中。成功采用完全定制训练模型的组织通常拥有大量的专有数据——数百万个示例或数十亿个令牌，他们希望使用这些数据来教授模型新知识或复杂、独特的行为，以用于高度特定的用例。

例如，AI 原生法律工具 [Harvey](https://www.harvey.ai/) 与 OpenAI 合作，[为案例法创建了一个定制训练的大型语言模型](https://openai.com/customer-stories/harvey)。虽然基础模型在推理方面表现强劲，但它们缺乏用于法律工作所需的广泛的法律案例历史和其他知识。在尝试过提示工程、RAG 和微调之后，Harvey 与我们的团队合作，将所需的深度上下文添加到模型中——相当于 100 亿个令牌的数据量。我们的团队修改了模型训练过程的每一个步骤，从领域特定的中训练到定制训练后过程，并纳入了专家律师的反馈。最终的模型在事实回应方面取得了 83% 的提升，律师们 97% 的时间更倾向于使用定制模型的输出，而不是 GPT-4。

![Harvey Sbs](../../assets/88/harvey-optimized.gif)

## 模型定制的未来发展

我们相信，在未来，绝大多数组织都会开发定制模型，这些模型针对他们的行业、业务或用例进行了个性化。通过多种技术可以构建一个定制模型，各种规模的组织都可以开发个性化模型，从而实现更有意义、更具体的 AI 实施影响。关键是要明确范围定义用例，设计和实施评估系统，选择正确的技术，并准备随着时间的推移迭代，以便模型达到最优性能。

通过 OpenAI，大多数组织可以通过自助微调 API 快速看到有意义的结果。对于任何需要更深入微调模型或将新的、特定于领域的知识注入模型的组织，我们的定制模型计划可以提供帮助。

访问我们的[微调 API](https://platform.openai.com/docs/guides/fine-tuning)文档以开始微调我们的模型。要了解更多关于我们如何帮助您定制模型以满足您的用例，请[联系我们](https://openai.com/form/custom-models)。
